{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","machine_shape":"hm","mount_file_id":"1W7eH9TgIpCFx80dxV26oMLEqOQkGg2rr","authorship_tag":"ABX9TyOOl8KHOLqNmYN4kV4yNWx9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 1. ë‹¤ì¤‘ Aspect ê²€ì¶œ ë¡œì§"],"metadata":{"id":"fH0XB7ThHdVU"}},{"cell_type":"code","source":["import pandas as pd\n","from pathlib import Path\n","import yaml\n","import re\n","from typing import Dict, Tuple\n","\n","import re\n","import yaml\n","from pathlib import Path\n","from typing import Dict, List, Tuple\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# 1. ì„¤ì • ê°’\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","BRAND_YML = Path(\n","    \"/content/drive/MyDrive/9. Lab/BARQA/Packaging & Download/Data/brands_0519.yaml\"\n",")\n","ASPT_YML = Path(\n","    \"/content/drive/MyDrive/9. Lab/BARQA/Packaging & Download/Data/aspects_0519.yaml\"\n",")\n","\n","# ì‚¼ì„± ê¸°ê¸°ì—ì„œë§Œ ì˜ë¯¸ê°€ ìˆëŠ” ì „ìš© ì–´ìŠ¤í™íŠ¸\n","SAMSUNG_REQ_ASP = {\n","    \"Camera General\", \"Design General\", \"Chipset General\",\n","    \"Sustainability General\", \"Portrait Studio\",\n","    \"On-device\", \"Grip\", \"Thin\", \"Galaxy AI General\",\n","}\n","\n","SAMSUNG_KW_RX = re.compile(r\"(?i)\\b(?:samsung|samsung's|galaxy|ê°¤ëŸ­ì‹œ|ì‚¼ì„±)\\b\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# 2. ë³´ì¡° í•¨ìˆ˜\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","def _load_yaml(path: Path) -> Dict[str, str]:\n","    \"\"\"YAML íŒŒì¼ì„ dictë¡œ ë¡œë“œ\"\"\"\n","    with path.open(encoding=\"utf-8\") as f:\n","        return yaml.safe_load(f)\n","\n","def _compile_dict(src: Dict[str, str], flags: int = 0) -> Dict[str, re.Pattern]:\n","    \"\"\"ì •ê·œí‘œí˜„ì‹ ë¬¸ìì—´ ë”•ì…”ë„ˆë¦¬ë¥¼ ì»´íŒŒì¼í•˜ì—¬ ë°˜í™˜\"\"\"\n","    return {k: re.compile(v, flags) for k, v in src.items()}\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# 3. ë©”ì¸ í´ë˜ìŠ¤\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","class BrandClassifier:\n","    def __init__(self) -> None:\n","        self.brand_rx  = _compile_dict(_load_yaml(BRAND_YML), flags=re.I)\n","        self.aspect_rx = _compile_dict(_load_yaml(ASPT_YML), flags=re.I)\n","\n","\n","    def classify(\n","        self, text: str, used_llm: bool = False\n","    ) -> Tuple[List[str], List[str], List[str], List[str]]:\n","        \"\"\"ë¬¸ì¥ì—ì„œ ë¸Œëœë“œ/ì–´ìŠ¤í™íŠ¸ë¥¼ ì¶”ì¶œí•´ 4-íŠœí”Œë¡œ ë°˜í™˜\"\"\"\n","\n","        brand_hits   = [(br, m.start()) for br, rx in self.brand_rx.items() if (m := rx.search(text))]\n","        aspect_hits  = [(ap, m.start()) for ap, rx in self.aspect_rx.items()  if (m := rx.search(text))]\n","\n","        brand_hits.sort(key=lambda x: x[1])\n","        aspect_hits.sort(key=lambda x: x[1])\n","\n","        detected_brands   = [b for b, _ in brand_hits]\n","        detected_aspects  = [a for a, _ in aspect_hits]\n","\n","        # 2) ì‚¼ì„± ì „ìš© ì–´ìŠ¤í™íŠ¸ ë³´ì •\n","        final_brands, final_aspects = [], []\n","        for asp in detected_aspects:\n","            if asp not in SAMSUNG_REQ_ASP:\n","                # ì¼ë°˜ ì–´ìŠ¤í™íŠ¸ â†’ ë¸Œëœë“œê°€ ëª…ì‹œ ì•ˆ ë¼ë„ Samsungìœ¼ë¡œ ìš°ì„  ì§€ì •\n","                final_brands.append(\"Samsung\")\n","                final_aspects.append(asp)\n","            else:\n","                # ì‚¼ì„± ì „ìš© ì–´ìŠ¤í™íŠ¸ëŠ” ì‹¤ì œ ì‚¼ì„± ì–¸ê¸‰ì´ ìˆëŠ”ì§€ í™•ì¸\n","                if \"Samsung\" in detected_brands or SAMSUNG_KW_RX.search(text):\n","                    final_brands.append(\"Samsung\")\n","                    final_aspects.append(asp)\n","                else:\n","                    # ë¬´íš¨ í”Œë˜ê·¸ë§Œ ë‚¨ê²¨ íœ´ë¨¼ í›„ì²˜ë¦¬ ê°€ëŠ¥í•˜ê²Œ\n","                    final_brands.append(\"Unknown\")\n","                    final_aspects.append(\"brand_required_aspect_detected\")\n","\n","        # 3) ì–´ìŠ¤í™íŠ¸ ì—†ìŒ & ë¸Œëœë“œë§Œ ìˆëŠ” ê²½ìš° ë³´ì™„\n","        if not detected_aspects and detected_brands:\n","            final_brands  = list(set(detected_brands))\n","            final_aspects = final_brands.copy()\n","\n","        # 4) ê¸°ë³¸ê°’ ë³´ì •\n","        if not final_brands:\n","            final_brands = [\"Unknown\"]\n","        if not final_aspects:\n","            final_aspects = [\"general\"]\n","\n","        # 5) ì‚¼ì„± ì™¸ ë¸Œëœë“œë„ ì–´ìŠ¤í™íŠ¸ë¡œ ì¶”ê°€\n","        others = [b for b in detected_brands if b != \"Samsung\"]\n","        final_brands.extend(others)\n","        final_aspects.extend(others)\n","\n","        # 6) ì •ë¦¬: ì¤‘ë³µÂ·ë³´ì¡° í† í° ì œê±°\n","        final_brands  = [b for b in dict.fromkeys(final_brands)  if b != \"Unknown\"]\n","        final_aspects = [\n","            a for a in dict.fromkeys(final_aspects)\n","            if a not in {\"Unknown\", \"brand_required_aspect_detected\"}\n","        ]\n","\n","        return final_brands, final_aspects, detected_brands, detected_aspects\n","\n","\n","# # YAML ê²½ë¡œ\n","# BRAND_YML = Path(\"/content/drive/MyDrive/9. Lab/BARQA/Packaging & Download/Data/brands_0519.yaml\")\n","# ASPT_YML  = Path(\"/content/drive/MyDrive/9. Lab/BARQA/Packaging & Download/Data/aspects_0519.yaml\")\n","\n","# def _load_yaml(path: Path) -> Dict[str, str]:\n","#     with path.open(encoding=\"utf-8\") as f:\n","#         return yaml.safe_load(f)\n","\n","# def _compile_dict(pattern_src: Dict[str, str],\n","#                   flags: int = 0) -> Dict[str, re.Pattern]:\n","#     return {k: re.compile(v, flags) for k, v in pattern_src.items()}\n","\n","# class BrandClassifier:\n","#     def __init__(self) -> None:\n","#         brand_src   = _load_yaml(BRAND_YML)\n","#         aspect_src  = _load_yaml(ASPT_YML)\n","\n","#         self.brand_rx  = _compile_dict(brand_src)\n","#         self.aspect_rx = _compile_dict(aspect_src)\n","#         self._samsung_kw_rx = re.compile(r\"(?i)\\b(?:samsung|samsung's|galaxy|ê°¤ëŸ­ì‹œ|ì‚¼ì„±)\\b\")\n","\n","#     def classify(self, text: str, used_llm: bool = False) -> Tuple[list, list]:\n","#         samsung_required_asp = [\n","#             'Camera General', 'Design General', 'Chipset General',\n","#             'Sustainability General', 'Portrait Studio',\n","#             'On-device', 'Grip', \"Thin\", \"Galaxy AI General\"\n","#         ]\n","\n","#         brand_hits = []\n","#         aspect_hits = []\n","\n","#         # 1. ëª¨ë“  ë¸Œëœë“œ íƒìƒ‰\n","#         for brand, rx in self.brand_rx.items():\n","#             match = rx.search(text)\n","#             if match:\n","#                 brand_hits.append((brand, match.start()))\n","\n","#         # 2. ëª¨ë“  ì–´ìŠ¤í™íŠ¸ íƒìƒ‰\n","#         for asp, arx in self.aspect_rx.items():\n","#             match = arx.search(text)\n","#             if match:\n","#                 aspect_hits.append((asp, match.start()))\n","\n","#         # 3. ì •ë ¬ (ë“±ì¥ ìˆœì„œ ê¸°ì¤€)\n","#         brand_hits.sort(key=lambda x: x[1])\n","#         aspect_hits.sort(key=lambda x: x[1])\n","\n","#         # 4. ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ\n","#         detected_brands = [b for b, _ in brand_hits]\n","#         detected_aspects = [a for a, _ in aspect_hits]\n","\n","#         # 5. ë¡œì§ ì ìš©: ì‚¼ì„± ì „ìš© aspect ì²˜ë¦¬\n","#         final_brands = []\n","#         final_aspects = []\n","\n","#         for asp in detected_aspects:\n","#             if asp not in samsung_required_asp:\n","#                 final_aspects.append(asp)\n","#                 final_brands.append(\"Samsung\")\n","\n","#                 # ì‚¼ì„± ì „ìš© ì•„ë‹˜ â†’ ë¸Œëœë“œ ì—†ì´ë„ í—ˆìš© (ë˜ëŠ” Samsungìœ¼ë¡œ ê°€ì •í•  ìˆ˜ë„ ìˆìŒ)\n","#             else:\n","#                 if \"Samsung\" in detected_brands or self._samsung_kw_rx.search(text):\n","#                     final_aspects.append(asp)\n","#                     final_brands.append(\"Samsung\")\n","#                 else:\n","#                     # ì‚¼ì„± í‚¤ì›Œë“œ ì—†ìœ¼ë©´ í•´ë‹¹ aspectëŠ” ë¬´íš¨ ì²˜ë¦¬ or íŠ¹ë³„íˆ í‘œê¸°\n","#                     final_aspects.append(\"brand_required_aspect_detected\")\n","#                     final_brands.append(\"Unknown\")\n","\n","#         # 6. í›„ì²˜ë¦¬\n","\n","#         if not detected_aspects and detected_brands:\n","#           final_aspects = list(set(detected_brands))\n","#           final_brands = list(set(detected_brands))\n","\n","#         if not final_brands:\n","#             final_brands = {\"Unknown\"}\n","\n","#         if not final_aspects:\n","#           if final_brands:\n","#             final_aspects = list(final_brands)\n","#           else:\n","#             final_aspects = [\"general\"]\n","#         else:\n","#           remain = [b for b in detected_brands if b != \"Samsung\"]\n","#           final_aspects.extend(remain)\n","#           final_brands.extend(remain)\n","\n","#         final_brands = [ a for a in final_brands if a not in {\"Unknown\"}]\n","#         final_aspects = [ a for a in final_aspects if a not in {\"Unknown\",\"brand_required_aspect_detected\"}]\n","\n","#         return list(final_brands), final_aspects, detected_brands, detected_aspects"],"metadata":{"id":"xctiTwTpqB1w","executionInfo":{"status":"ok","timestamp":1751875446329,"user_tz":-540,"elapsed":58,"user":{"displayName":"KEARNEY SEMX","userId":"06834010073227309486"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## Sample Test"],"metadata":{"id":"jA0HQmA0gVHl"}},{"cell_type":"code","source":["classifier = BrandClassifier()\n","# txt = (\"If you want to find out about the camera, processor and â€“ especially â€“ AI improvements in those devices, read our hands-on Samsung Galaxy S25 review, hands-on Samsung Galaxy S25 Plus review and our hands-on Samsung Galaxy S25 Ultra review.\")\n","txt = \"\"\"From the city streets to the open road, Changanâ€™s electric vehicles have managed to combine sleek design, rugged capability, and sophisticated technology.\"\"\"\n","brands, aspects, detected_b, detected_a = classifier.classify(txt)\n","\n","print(\"ğŸ“¦ ë¸Œëœë“œ ëª©ë¡:\", brands)      # ['Samsung', 'Samsung', 'Apple']\n","print(\"ğŸ§© ì–´ìŠ¤í™íŠ¸ ëª©ë¡:\", aspects)    # ['Thin', 'Galaxy AI General', 'Apple']\n","print(\"- Raw ë¸Œëœë“œ :\", detected_b)   # ['Samsung', 'Apple']\n","print(\"- Raw ì–´ìŠ¤í™íŠ¸ :\", detected_a) # ['Thin', 'Galaxy AI General']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c4s97PEgqM5o","executionInfo":{"status":"ok","timestamp":1751875451241,"user_tz":-540,"elapsed":1365,"user":{"displayName":"KEARNEY SEMX","userId":"06834010073227309486"}},"outputId":"4dc5c0a2-60fc-4eb4-d809-ae82a9c52001"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ“¦ ë¸Œëœë“œ ëª©ë¡: []\n","ğŸ§© ì–´ìŠ¤í™íŠ¸ ëª©ë¡: []\n","- Raw ë¸Œëœë“œ : []\n","- Raw ì–´ìŠ¤í™íŠ¸ : ['Design General']\n"]}]},{"cell_type":"markdown","source":["# 3. [Package ì½”ë“œ] ë‹¤ì¤‘ aspectì— ëŒ€í•œ í–‰ ë¶„ë¦¬"],"metadata":{"id":"8Pt7-yjytF2L"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from pathlib import Path\n","from google.colab import drive\n","\n","MODE = \"prod\"\n","drive.mount(\"/content/drive\")\n","\n","INPUT_PATH = Path(\"/content/translated_crawl_results.xlsx\")\n","df = pd.read_excel(INPUT_PATH) #main ë¯¸ì‚¬ìš©ì‹œ\n","\n","if MODE == \"dev\":\n","    df[\"True_Aspect\"] = df[\"Aspect\"].fillna(df[\"Keywords(Company)\"])\n","    df.drop_duplicates(['Media Title', 'Conversation Stream', 'True_Aspect'], inplace=True)\n","\n","clf = BrandClassifier()\n","rows = []\n","\n","for conv_id, g in df.groupby(\"Conversation Stream\", sort=False):\n","    pred_brands, pred_aspects, *_ = clf.classify(str(conv_id))\n","    url = g[\"url\"].iloc[0] if \"url\" in g.columns else np.nan\n","    pred_map = {asp.casefold(): br for br, asp in zip(pred_brands, pred_aspects)}\n","\n","    if MODE == \"dev\":\n","        for true_val, senti in zip(g[\"True_Aspect\"], g[\"Sentiment\"]):\n","            norm_true = str(true_val).strip().casefold()\n","            if norm_true in pred_map:\n","                rows.append((g[\"Media Title\"].iloc[0], conv_id, true_val, norm_true, pred_map[norm_true], senti, url))\n","                del pred_map[norm_true]\n","            else:\n","                rows.append((g[\"Media Title\"].iloc[0], conv_id, true_val, np.nan, np.nan, senti, url))\n","\n","    if MODE == \"prod\" and not pred_map:\n","        rows.append((g[\"Media Title\"].iloc[0], conv_id, np.nan, np.nan, url))\n","\n","    for asp_cf, br in pred_map.items():\n","        asp = next(a for a in pred_aspects if a.casefold() == asp_cf)\n","        if MODE == \"dev\":\n","            rows.append((g[\"Media Title\"].iloc[0], conv_id, np.nan, asp, br, \"NEED_LABELING\", url))\n","        else:\n","            rows.append((g[\"Media Title\"].iloc[0], conv_id, asp, br, url))\n","\n","if MODE == \"dev\":\n","    df_expanded = pd.DataFrame(\n","        rows,\n","        columns=[\n","            \"Media Title\",\n","            \"Conversation Stream\",\n","            \"True_Aspect\",\n","            \"Predicted_Aspect\",\n","            \"Predicted_Brand\",\n","            \"True_Sentiment\",\n","            \"url\"\n","        ],\n","    )\n","else:\n","    df_expanded = pd.DataFrame(\n","        rows,\n","        columns=[\n","            \"Media Title\",\n","            \"Conversation Stream\",\n","            \"Predicted_Aspect\",\n","            \"Predicted_Brand\",\n","            \"url\"\n","        ],\n","    )\n","\n","\n","df_implicit = df_expanded.copy()\n","\n","# ëª…ì‹œì  (explicit) íŒë‹¨ ê¸°ì¤€: 'Predicted_Aspect'ê°€ 'general'ì´ ì•„ë‹˜\n","df_explicit = df_expanded[\n","    df_expanded[\"Predicted_Aspect\"].notna() &\n","    (df_expanded[\"Predicted_Aspect\"].str.lower() != \"general\")\n","].copy()\n","\n","# íŒŒì¼ ê²½ë¡œ ì„¤ì •\n","OUTPUT_PATH_1 = \"/content/implicit_case.xlsx\"\n","OUTPUT_PATH_2 = \"/content/Aspect_Extraction_explicit.xlsx\"\n","\n","df_implicit.to_excel(OUTPUT_PATH_1, index=False, engine=\"openpyxl\")\n","df_explicit.to_excel(OUTPUT_PATH_2, index=False, engine=\"openpyxl\")\n"],"metadata":{"id":"VG1rX4thdRuK","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fb051d49-6c88-4a1a-b3df-9cfc0dc2caaf","executionInfo":{"status":"ok","timestamp":1751875508988,"user_tz":-540,"elapsed":56909,"user":{"displayName":"KEARNEY SEMX","userId":"06834010073227309486"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["## dev ëª¨ë“œì¼ ê²½ìš°, íœ´ë¨¼ì—ëŸ¬ ì „ì²˜ë¦¬"],"metadata":{"id":"D23hgVQ8Ejba"}},{"cell_type":"code","source":["if MODE == \"dev\":\n","  df_dev = df_expanded.copy()\n","else:\n","  df_prod = df_expanded.copy()"],"metadata":{"id":"nvajDOPR4akq","colab":{"base_uri":"https://localhost:8080/","height":193},"executionInfo":{"status":"error","timestamp":1750902325739,"user_tz":-540,"elapsed":16,"user":{"displayName":"KEARNEY SEMX","userId":"06834010073227309486"}},"outputId":"6442b2dc-9cee-456c-8463-e2fa7ce8ac37"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'df_expanded' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-24-384331964.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mMODE\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"dev\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mdf_dev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_expanded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mdf_prod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_expanded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'df_expanded' is not defined"]}]},{"cell_type":"code","source":["if MODE == \"dev\":\n","    df_dev_processed = df_dev.copy()\n","    df_dev_processed[\"ìˆ˜ê¸° ë¼ë²¨ë§\"] = False\n","    df_dev_processed[\"Implicit\"] = False\n","\n","    drop_list   = []          # ë‚˜ì¤‘ì— í•œêº¼ë²ˆì— ì‚­ì œ\n","    update_rows = {}          # {ëŒ€ìƒì¸ë±ìŠ¤ë“¤: ìƒˆ Predicted ê°’}\n","\n","    for cid, grp in df_dev_processed.groupby(\"Conversation Stream\"):\n","\n","      # 1) ë‹¨ì¼ í–‰ & ìˆ˜ê¸° ë¼ë²¨ë§\n","      if len(grp) == 1:\n","          i = grp.index[0]\n","\n","          # a) ìˆ˜ê¸° ë¼ë²¨ë§\n","          if pd.isna(grp.at[i, \"True_Aspect\"]) and pd.notna(grp.at[i, \"Predicted_Aspect\"]):\n","              df_dev_processed.at[i, \"ìˆ˜ê¸° ë¼ë²¨ë§\"] = True\n","\n","          # b) Implicit í”Œë˜ê·¸\n","          if pd.isna(grp.at[i, \"Predicted_Aspect\"]):\n","              df_dev_processed.at[i, \"Implicit\"] = True\n","          continue  # ë‹¨ì¼ í–‰ ê·¸ë£¹ì€ ì—¬ê¸°ì„œ ë\n","\n","      # 2) Samsung í–‰ ì—¬ë¶€\n","      mask_s = grp[\"True_Aspect\"].astype(str).str.strip().str.casefold() == \"samsung\"\n","      samsung_idx = grp.index[mask_s]\n","\n","      if len(samsung_idx):\n","          # a) ì‚­ì œ ì˜ˆì•½\n","          drop_list.extend(samsung_idx)\n","\n","          # b) 'True_Aspectê°€ NaN ì´ê³  Predicted_AspectëŠ” notna' í–‰ë§Œ ê³¨ë¼ True_Aspect ì±„ìš°ê¸°\n","          cond_fill = grp.index.difference(samsung_idx)          # (1) ì‚¼ì„±-í–‰ ì œì™¸\n","          cond_fill = cond_fill.intersection(                    # (2) ë‘ ì¡°ê±´ ëª¨ë‘ ë§Œì¡±\n","              grp.index[ grp[\"True_Aspect\"].isna()               #     Â· True_Aspect ê°€ NaN\n","                        & grp[\"Predicted_Aspect\"].notna() ]     #     Â· Predicted_Aspect ëŠ” ê°’ì´ ìˆìŒ\n","          )\n","\n","          # (3) ì—…ë°ì´íŠ¸ ì˜ˆì•½: {í–‰ index : ìƒˆ True_Aspect ê°’(= Predicted_Aspect)}\n","          update_true = {i: df_dev_processed.at[i, \"Predicted_Aspect\"] for i in cond_fill}\n","\n","          # (4) update_rows ì‚¬ì „ì— í•©ì³ ë‘ \n","          update_rows.update(update_true)\n","\n","          # â–¶ new: ê·¸ë£¹ ì „ì²´ì— \"if\" í‘œì‹œ\n","          df_dev_processed.loc[grp.index, \"Samsung_branch\"] = \"if_has_samsung\"\n","\n","\n","      # 3) ë¹„-Samsung í–‰ì´ë©´ì„œ Predictedë„ samsungì´ ì•„ë‹ ë•Œ\n","      else:\n","          # â”€â”€ 1) ì´ ê·¸ë£¹ì— Predicted_Aspect == 'samsung' ê°’ì´ ìˆëŠ”ì§€ í™•ì¸\n","          has_pa_samsung = (\n","              grp[\"Predicted_Aspect\"]\n","              .astype(str).str.strip().str.casefold()\n","              .eq(\"samsung\")\n","          ).any()\n","\n","          if not has_pa_samsung:                             # â–¸ í•œ ê°œë„ ì—†ì„ ë•Œë§Œ ì‹¤í–‰\n","              # (1) Predicted_Aspect ê°€ NaN ì´ ì•„ë‹Œ í–‰ë§Œ ê³¨ë¼ì„œ\n","              mask_notna = df_dev_processed.loc[grp.index, \"Predicted_Aspect\"].notna()\n","              target_idx = grp.index[mask_notna]\n","\n","              # ê·¸ë£¹ ëª¨ë“  í–‰ì˜ Predicted_Aspect â† ê°™ì€ í–‰ì˜ True_Aspect\n","              df_dev_processed.loc[target_idx, \"True_Aspect\"] = (\n","                  df_dev_processed.loc[target_idx, \"Predicted_Aspect\"]\n","              )\n","          # â–¶ new: ê·¸ë£¹ ì „ì²´ì— \"else_no_samsung\" í‘œì‹œ\n","          df_dev_processed.loc[grp.index, \"Samsung_branch\"] = \"else_no_samsung\"\n","\n","    # â”€â”€ ì¼ê´„ ì ìš© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","    if drop_list:\n","      df_dev_processed.drop(index=drop_list, inplace=True)\n","\n","    for j, new_val in update_rows.items():\n","      if j in df_dev_processed.index:                               # ì¡´ì¬ í™•ì¸\n","          df_dev_processed.at[j, \"True_Aspect\"] = new_val\n","\n","    # â”€â”€ (dev) Explicit & Implicit ë¶„ë¦¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","    df_dev_explicit = df_dev_processed[df_dev_processed['Implicit']==False]\n","    df_implicit = df_dev_processed[df_dev_processed['Implicit']==True]"],"metadata":{"id":"8W4QmSV_aQkY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","def merge_rows(g: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"\n","    ê·¸ë£¹ g(ê°™ì€ Conversation  Stream)ë¥¼ ë°›ì•„ì„œ\n","    ì¡°ê±´ì— ë§ìœ¼ë©´ 2í–‰ â†’ 1í–‰ìœ¼ë¡œ ì¶•ì†Œ, ì•„ë‹ˆë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜\n","    \"\"\"\n","    if len(g) == 2:\n","        # NaN ì•„ë‹Œ ê°’ì´ ì •í™•íˆ í•˜ë‚˜ì”© ìˆëŠ”ì§€ í™•ì¸\n","        true_vals = g[\"True_Aspect\"].dropna().unique()\n","        true_sent = g[\"True_Sentiment\"].dropna().unique()\n","        pred_vals = g[\"Predicted_Aspect\"].dropna().unique()\n","        pred_brands = g[\"Predicted_Brand\"].dropna().unique()\n","\n","        if len(true_vals) == 1 and len(pred_vals) == 1:\n","            # ìƒˆ í–‰ ë§Œë“¤ê¸°: ì›ë³¸ ì²« í–‰ì„ ë³µì‚¬í•´ ê°’ ì±„ì›€\n","            new_row = g.iloc[0].copy()\n","            new_row[\"True_Aspect\"]      = true_vals[0]\n","            new_row[\"Predicted_Aspect\"] = pred_vals[0]\n","            new_row[\"Predicted_Brand\"]   = pred_brands[0]\n","            new_row[\"True_Sentiment\"]    = true_sent[0]\n","            return pd.DataFrame([new_row])   # 1í–‰ì§œë¦¬ DF ë°˜í™˜\n","\n","    # ì¡°ê±´ì„ ë§Œì¡±í•˜ì§€ ì•Šìœ¼ë©´ ì›ë³¸ ê·¸ëŒ€ë¡œ\n","    return g\n","\n","if MODE == \"dev\":\n","  df_explicit = (\n","      df_dev_explicit\n","        .groupby(\"Conversation Stream\", group_keys=False)\n","        .apply(merge_rows)\n","        .reset_index(drop=True)          # ì„ íƒ: ì¸ë±ìŠ¤ ì¬ì •ë ¬\n","  )"],"metadata":{"id":"vagVMLUqt5ge"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if MODE == \"prod\":\n","  df_implicit = df_prod[df_prod['Predicted_Aspect'].isna()]\n","  df_explicit = df_prod[~(df_prod['Predicted_Aspect'].isna())]"],"metadata":{"id":"_XXbBW3nxwI4","colab":{"base_uri":"https://localhost:8080/","height":176},"executionInfo":{"status":"error","timestamp":1751601601734,"user_tz":-540,"elapsed":70,"user":{"displayName":"KEARNEY SEMX","userId":"06834010073227309486"}},"outputId":"e3841b01-1433-4779-fd9a-b512104595d5"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'df_prod' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-6-701549432.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mMODE\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"prod\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mdf_implicit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_prod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_prod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Predicted_Aspect'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mdf_explicit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_prod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_prod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Predicted_Aspect'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'df_prod' is not defined"]}]},{"cell_type":"code","source":["df_implicit.to_excel(f\"{OUTPUT_PATH_1}\", index=False)\n","df_explicit.to_excel(f\"{OUTPUT_PATH_2}\", index=False)"],"metadata":{"id":"V4eGRMtNTBRh","colab":{"base_uri":"https://localhost:8080/","height":158},"executionInfo":{"status":"error","timestamp":1751601609620,"user_tz":-540,"elapsed":23,"user":{"displayName":"KEARNEY SEMX","userId":"06834010073227309486"}},"outputId":"0970bf24-4e29-4b66-e34d-254374e61b1e"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'df_implicit' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-7-2045134337.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_implicit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{OUTPUT_PATH_1}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_explicit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{OUTPUT_PATH_2}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'df_implicit' is not defined"]}]},{"cell_type":"markdown","source":["# ì°¸ê³ . Sentiment Analysis ëª¨ë¸ë§ì„ ìœ„í•œ ì „ì²˜ë¦¬ (ë¼ë²¨ë§ ë°ì´í„°ì— ë¼ì›Œë§ì¶”ê¸°)"],"metadata":{"id":"WviIrv5cSCtK"}},{"cell_type":"code","source":["# # True_Aspectì— ê°’ì´ ìˆê³  Predicted_Aspectì™€ ë™ì¼í•œ í–‰ì˜ ê°œìˆ˜ ê³„ì‚°\n","# count1 = len(df_expanded[(df_expanded['Predicted_Aspect'].notna()) & (df_expanded['True_Aspect'].apply(lambda x: str(x).strip().casefold()) == df_expanded['Predicted_Aspect'].apply(lambda x: str(x).strip().casefold()))])\n","# print(f\"True_Aspect = Predicted_Aspect í–‰ì˜ ê°œìˆ˜ (Package ì½”ë“œ): {count1}\")\n","# count2 = len(df_explicit[(df_explicit['True_Aspect'].apply(lambda x: str(x).strip().casefold()) == df_explicit['Predicted_Aspect'].apply(lambda x: str(x).strip().casefold()))])\n","# print(f\"True_Aspect = Predicted_Aspect í–‰ì˜ ê°œìˆ˜ (Package ì½”ë“œ): {count2}\")"],"metadata":{"id":"WwvGCaoxymMS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # 1. ì—‘ì…€ íŒŒì¼ ë¡œë“œ\n","# df = pd.read_excel(\"(raw-2) 0523_S_core_explicit (ìˆ˜ì •).xlsx\")  # íŒŒì¼ëª…ì— ë§ê²Œ ê²½ë¡œ ìˆ˜ì •\n","\n","# # 2. ë¶„ë¥˜ê¸° ì¸ìŠ¤í„´ìŠ¤\n","# classifier = BrandClassifier()\n","\n","# # 3. ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸\n","# wrong_predictions = []\n","\n","# # 4. ê° í–‰ë§ˆë‹¤ ë¶„ë¥˜í•˜ê³ , ì˜¤ë‹µì¼ ê²½ìš°ë§Œ ì €ì¥\n","# for i, row in df.iterrows():\n","#     text = str(row[\"Conversation Stream\"])\n","#     true_aspect = str(row[\"True_Aspect\"]).strip().casefold()\n","#     company = row.get(\"Keywords(Company)\", \"\")\n","\n","#     brands, aspects, detected_brands, detected_aspects = classifier.classify(text)\n","\n","#     true_list = list(map(lambda x : x.strip().casefold(), brands)) + list(map(lambda x: x.strip().casefold(), aspects))\n","\n","#     # ì¡°ê±´ ë§Œì¡± ì‹œ Predicted_Aspectë¥¼ True_Aspectë¡œ ë®ì–´ì“°ê¸°\n","#     if true_aspect in true_list:\n","#         df.at[i, \"Predicted_Aspect\"] = df.at[i, \"True_Aspect\"]\n","#         df.at[i, \"Modified\"] = True\n","\n","# df_a = df.copy()\n","# len(df[df[\"Predicted_Aspect\"]==df[\"True_Aspect\"]])"],"metadata":{"id":"ixWtjbNwtOVf"},"execution_count":null,"outputs":[]}]}