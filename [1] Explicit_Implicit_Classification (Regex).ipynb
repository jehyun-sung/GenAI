{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","machine_shape":"hm","mount_file_id":"1W7eH9TgIpCFx80dxV26oMLEqOQkGg2rr","authorship_tag":"ABX9TyOOl8KHOLqNmYN4kV4yNWx9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 1. 다중 Aspect 검출 로직"],"metadata":{"id":"fH0XB7ThHdVU"}},{"cell_type":"code","source":["import pandas as pd\n","from pathlib import Path\n","import yaml\n","import re\n","from typing import Dict, Tuple\n","\n","import re\n","import yaml\n","from pathlib import Path\n","from typing import Dict, List, Tuple\n","\n","# ──────────────────────────────────────────────────────────────\n","# 1. 설정 값\n","# ──────────────────────────────────────────────────────────────\n","BRAND_YML = Path(\n","    \"/content/drive/MyDrive/9. Lab/BARQA/Packaging & Download/Data/brands_0519.yaml\"\n",")\n","ASPT_YML = Path(\n","    \"/content/drive/MyDrive/9. Lab/BARQA/Packaging & Download/Data/aspects_0519.yaml\"\n",")\n","\n","# 삼성 기기에서만 의미가 있는 전용 어스펙트\n","SAMSUNG_REQ_ASP = {\n","    \"Camera General\", \"Design General\", \"Chipset General\",\n","    \"Sustainability General\", \"Portrait Studio\",\n","    \"On-device\", \"Grip\", \"Thin\", \"Galaxy AI General\",\n","}\n","\n","SAMSUNG_KW_RX = re.compile(r\"(?i)\\b(?:samsung|samsung's|galaxy|갤럭시|삼성)\\b\")\n","\n","# ──────────────────────────────────────────────────────────────\n","# 2. 보조 함수\n","# ──────────────────────────────────────────────────────────────\n","def _load_yaml(path: Path) -> Dict[str, str]:\n","    \"\"\"YAML 파일을 dict로 로드\"\"\"\n","    with path.open(encoding=\"utf-8\") as f:\n","        return yaml.safe_load(f)\n","\n","def _compile_dict(src: Dict[str, str], flags: int = 0) -> Dict[str, re.Pattern]:\n","    \"\"\"정규표현식 문자열 딕셔너리를 컴파일하여 반환\"\"\"\n","    return {k: re.compile(v, flags) for k, v in src.items()}\n","\n","# ──────────────────────────────────────────────────────────────\n","# 3. 메인 클래스\n","# ──────────────────────────────────────────────────────────────\n","class BrandClassifier:\n","    def __init__(self) -> None:\n","        self.brand_rx  = _compile_dict(_load_yaml(BRAND_YML), flags=re.I)\n","        self.aspect_rx = _compile_dict(_load_yaml(ASPT_YML), flags=re.I)\n","\n","\n","    def classify(\n","        self, text: str, used_llm: bool = False\n","    ) -> Tuple[List[str], List[str], List[str], List[str]]:\n","        \"\"\"문장에서 브랜드/어스펙트를 추출해 4-튜플로 반환\"\"\"\n","\n","        brand_hits   = [(br, m.start()) for br, rx in self.brand_rx.items() if (m := rx.search(text))]\n","        aspect_hits  = [(ap, m.start()) for ap, rx in self.aspect_rx.items()  if (m := rx.search(text))]\n","\n","        brand_hits.sort(key=lambda x: x[1])\n","        aspect_hits.sort(key=lambda x: x[1])\n","\n","        detected_brands   = [b for b, _ in brand_hits]\n","        detected_aspects  = [a for a, _ in aspect_hits]\n","\n","        # 2) 삼성 전용 어스펙트 보정\n","        final_brands, final_aspects = [], []\n","        for asp in detected_aspects:\n","            if asp not in SAMSUNG_REQ_ASP:\n","                # 일반 어스펙트 → 브랜드가 명시 안 돼도 Samsung으로 우선 지정\n","                final_brands.append(\"Samsung\")\n","                final_aspects.append(asp)\n","            else:\n","                # 삼성 전용 어스펙트는 실제 삼성 언급이 있는지 확인\n","                if \"Samsung\" in detected_brands or SAMSUNG_KW_RX.search(text):\n","                    final_brands.append(\"Samsung\")\n","                    final_aspects.append(asp)\n","                else:\n","                    # 무효 플래그만 남겨 휴먼 후처리 가능하게\n","                    final_brands.append(\"Unknown\")\n","                    final_aspects.append(\"brand_required_aspect_detected\")\n","\n","        # 3) 어스펙트 없음 & 브랜드만 있는 경우 보완\n","        if not detected_aspects and detected_brands:\n","            final_brands  = list(set(detected_brands))\n","            final_aspects = final_brands.copy()\n","\n","        # 4) 기본값 보정\n","        if not final_brands:\n","            final_brands = [\"Unknown\"]\n","        if not final_aspects:\n","            final_aspects = [\"general\"]\n","\n","        # 5) 삼성 외 브랜드도 어스펙트로 추가\n","        others = [b for b in detected_brands if b != \"Samsung\"]\n","        final_brands.extend(others)\n","        final_aspects.extend(others)\n","\n","        # 6) 정리: 중복·보조 토큰 제거\n","        final_brands  = [b for b in dict.fromkeys(final_brands)  if b != \"Unknown\"]\n","        final_aspects = [\n","            a for a in dict.fromkeys(final_aspects)\n","            if a not in {\"Unknown\", \"brand_required_aspect_detected\"}\n","        ]\n","\n","        return final_brands, final_aspects, detected_brands, detected_aspects\n","\n","\n","# # YAML 경로\n","# BRAND_YML = Path(\"/content/drive/MyDrive/9. Lab/BARQA/Packaging & Download/Data/brands_0519.yaml\")\n","# ASPT_YML  = Path(\"/content/drive/MyDrive/9. Lab/BARQA/Packaging & Download/Data/aspects_0519.yaml\")\n","\n","# def _load_yaml(path: Path) -> Dict[str, str]:\n","#     with path.open(encoding=\"utf-8\") as f:\n","#         return yaml.safe_load(f)\n","\n","# def _compile_dict(pattern_src: Dict[str, str],\n","#                   flags: int = 0) -> Dict[str, re.Pattern]:\n","#     return {k: re.compile(v, flags) for k, v in pattern_src.items()}\n","\n","# class BrandClassifier:\n","#     def __init__(self) -> None:\n","#         brand_src   = _load_yaml(BRAND_YML)\n","#         aspect_src  = _load_yaml(ASPT_YML)\n","\n","#         self.brand_rx  = _compile_dict(brand_src)\n","#         self.aspect_rx = _compile_dict(aspect_src)\n","#         self._samsung_kw_rx = re.compile(r\"(?i)\\b(?:samsung|samsung's|galaxy|갤럭시|삼성)\\b\")\n","\n","#     def classify(self, text: str, used_llm: bool = False) -> Tuple[list, list]:\n","#         samsung_required_asp = [\n","#             'Camera General', 'Design General', 'Chipset General',\n","#             'Sustainability General', 'Portrait Studio',\n","#             'On-device', 'Grip', \"Thin\", \"Galaxy AI General\"\n","#         ]\n","\n","#         brand_hits = []\n","#         aspect_hits = []\n","\n","#         # 1. 모든 브랜드 탐색\n","#         for brand, rx in self.brand_rx.items():\n","#             match = rx.search(text)\n","#             if match:\n","#                 brand_hits.append((brand, match.start()))\n","\n","#         # 2. 모든 어스펙트 탐색\n","#         for asp, arx in self.aspect_rx.items():\n","#             match = arx.search(text)\n","#             if match:\n","#                 aspect_hits.append((asp, match.start()))\n","\n","#         # 3. 정렬 (등장 순서 기준)\n","#         brand_hits.sort(key=lambda x: x[1])\n","#         aspect_hits.sort(key=lambda x: x[1])\n","\n","#         # 4. 리스트 추출\n","#         detected_brands = [b for b, _ in brand_hits]\n","#         detected_aspects = [a for a, _ in aspect_hits]\n","\n","#         # 5. 로직 적용: 삼성 전용 aspect 처리\n","#         final_brands = []\n","#         final_aspects = []\n","\n","#         for asp in detected_aspects:\n","#             if asp not in samsung_required_asp:\n","#                 final_aspects.append(asp)\n","#                 final_brands.append(\"Samsung\")\n","\n","#                 # 삼성 전용 아님 → 브랜드 없이도 허용 (또는 Samsung으로 가정할 수도 있음)\n","#             else:\n","#                 if \"Samsung\" in detected_brands or self._samsung_kw_rx.search(text):\n","#                     final_aspects.append(asp)\n","#                     final_brands.append(\"Samsung\")\n","#                 else:\n","#                     # 삼성 키워드 없으면 해당 aspect는 무효 처리 or 특별히 표기\n","#                     final_aspects.append(\"brand_required_aspect_detected\")\n","#                     final_brands.append(\"Unknown\")\n","\n","#         # 6. 후처리\n","\n","#         if not detected_aspects and detected_brands:\n","#           final_aspects = list(set(detected_brands))\n","#           final_brands = list(set(detected_brands))\n","\n","#         if not final_brands:\n","#             final_brands = {\"Unknown\"}\n","\n","#         if not final_aspects:\n","#           if final_brands:\n","#             final_aspects = list(final_brands)\n","#           else:\n","#             final_aspects = [\"general\"]\n","#         else:\n","#           remain = [b for b in detected_brands if b != \"Samsung\"]\n","#           final_aspects.extend(remain)\n","#           final_brands.extend(remain)\n","\n","#         final_brands = [ a for a in final_brands if a not in {\"Unknown\"}]\n","#         final_aspects = [ a for a in final_aspects if a not in {\"Unknown\",\"brand_required_aspect_detected\"}]\n","\n","#         return list(final_brands), final_aspects, detected_brands, detected_aspects"],"metadata":{"id":"xctiTwTpqB1w","executionInfo":{"status":"ok","timestamp":1751875446329,"user_tz":-540,"elapsed":58,"user":{"displayName":"KEARNEY SEMX","userId":"06834010073227309486"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## Sample Test"],"metadata":{"id":"jA0HQmA0gVHl"}},{"cell_type":"code","source":["classifier = BrandClassifier()\n","# txt = (\"If you want to find out about the camera, processor and – especially – AI improvements in those devices, read our hands-on Samsung Galaxy S25 review, hands-on Samsung Galaxy S25 Plus review and our hands-on Samsung Galaxy S25 Ultra review.\")\n","txt = \"\"\"From the city streets to the open road, Changan’s electric vehicles have managed to combine sleek design, rugged capability, and sophisticated technology.\"\"\"\n","brands, aspects, detected_b, detected_a = classifier.classify(txt)\n","\n","print(\"📦 브랜드 목록:\", brands)      # ['Samsung', 'Samsung', 'Apple']\n","print(\"🧩 어스펙트 목록:\", aspects)    # ['Thin', 'Galaxy AI General', 'Apple']\n","print(\"- Raw 브랜드 :\", detected_b)   # ['Samsung', 'Apple']\n","print(\"- Raw 어스펙트 :\", detected_a) # ['Thin', 'Galaxy AI General']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c4s97PEgqM5o","executionInfo":{"status":"ok","timestamp":1751875451241,"user_tz":-540,"elapsed":1365,"user":{"displayName":"KEARNEY SEMX","userId":"06834010073227309486"}},"outputId":"4dc5c0a2-60fc-4eb4-d809-ae82a9c52001"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["📦 브랜드 목록: []\n","🧩 어스펙트 목록: []\n","- Raw 브랜드 : []\n","- Raw 어스펙트 : ['Design General']\n"]}]},{"cell_type":"markdown","source":["# 3. [Package 코드] 다중 aspect에 대한 행 분리"],"metadata":{"id":"8Pt7-yjytF2L"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from pathlib import Path\n","from google.colab import drive\n","\n","MODE = \"prod\"\n","drive.mount(\"/content/drive\")\n","\n","INPUT_PATH = Path(\"/content/translated_crawl_results.xlsx\")\n","df = pd.read_excel(INPUT_PATH) #main 미사용시\n","\n","if MODE == \"dev\":\n","    df[\"True_Aspect\"] = df[\"Aspect\"].fillna(df[\"Keywords(Company)\"])\n","    df.drop_duplicates(['Media Title', 'Conversation Stream', 'True_Aspect'], inplace=True)\n","\n","clf = BrandClassifier()\n","rows = []\n","\n","for conv_id, g in df.groupby(\"Conversation Stream\", sort=False):\n","    pred_brands, pred_aspects, *_ = clf.classify(str(conv_id))\n","    url = g[\"url\"].iloc[0] if \"url\" in g.columns else np.nan\n","    pred_map = {asp.casefold(): br for br, asp in zip(pred_brands, pred_aspects)}\n","\n","    if MODE == \"dev\":\n","        for true_val, senti in zip(g[\"True_Aspect\"], g[\"Sentiment\"]):\n","            norm_true = str(true_val).strip().casefold()\n","            if norm_true in pred_map:\n","                rows.append((g[\"Media Title\"].iloc[0], conv_id, true_val, norm_true, pred_map[norm_true], senti, url))\n","                del pred_map[norm_true]\n","            else:\n","                rows.append((g[\"Media Title\"].iloc[0], conv_id, true_val, np.nan, np.nan, senti, url))\n","\n","    if MODE == \"prod\" and not pred_map:\n","        rows.append((g[\"Media Title\"].iloc[0], conv_id, np.nan, np.nan, url))\n","\n","    for asp_cf, br in pred_map.items():\n","        asp = next(a for a in pred_aspects if a.casefold() == asp_cf)\n","        if MODE == \"dev\":\n","            rows.append((g[\"Media Title\"].iloc[0], conv_id, np.nan, asp, br, \"NEED_LABELING\", url))\n","        else:\n","            rows.append((g[\"Media Title\"].iloc[0], conv_id, asp, br, url))\n","\n","if MODE == \"dev\":\n","    df_expanded = pd.DataFrame(\n","        rows,\n","        columns=[\n","            \"Media Title\",\n","            \"Conversation Stream\",\n","            \"True_Aspect\",\n","            \"Predicted_Aspect\",\n","            \"Predicted_Brand\",\n","            \"True_Sentiment\",\n","            \"url\"\n","        ],\n","    )\n","else:\n","    df_expanded = pd.DataFrame(\n","        rows,\n","        columns=[\n","            \"Media Title\",\n","            \"Conversation Stream\",\n","            \"Predicted_Aspect\",\n","            \"Predicted_Brand\",\n","            \"url\"\n","        ],\n","    )\n","\n","\n","df_implicit = df_expanded.copy()\n","\n","# 명시적 (explicit) 판단 기준: 'Predicted_Aspect'가 'general'이 아님\n","df_explicit = df_expanded[\n","    df_expanded[\"Predicted_Aspect\"].notna() &\n","    (df_expanded[\"Predicted_Aspect\"].str.lower() != \"general\")\n","].copy()\n","\n","# 파일 경로 설정\n","OUTPUT_PATH_1 = \"/content/implicit_case.xlsx\"\n","OUTPUT_PATH_2 = \"/content/Aspect_Extraction_explicit.xlsx\"\n","\n","df_implicit.to_excel(OUTPUT_PATH_1, index=False, engine=\"openpyxl\")\n","df_explicit.to_excel(OUTPUT_PATH_2, index=False, engine=\"openpyxl\")\n"],"metadata":{"id":"VG1rX4thdRuK","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fb051d49-6c88-4a1a-b3df-9cfc0dc2caaf","executionInfo":{"status":"ok","timestamp":1751875508988,"user_tz":-540,"elapsed":56909,"user":{"displayName":"KEARNEY SEMX","userId":"06834010073227309486"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["## dev 모드일 경우, 휴먼에러 전처리"],"metadata":{"id":"D23hgVQ8Ejba"}},{"cell_type":"code","source":["if MODE == \"dev\":\n","  df_dev = df_expanded.copy()\n","else:\n","  df_prod = df_expanded.copy()"],"metadata":{"id":"nvajDOPR4akq","colab":{"base_uri":"https://localhost:8080/","height":193},"executionInfo":{"status":"error","timestamp":1750902325739,"user_tz":-540,"elapsed":16,"user":{"displayName":"KEARNEY SEMX","userId":"06834010073227309486"}},"outputId":"6442b2dc-9cee-456c-8463-e2fa7ce8ac37"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'df_expanded' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-24-384331964.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mMODE\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"dev\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mdf_dev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_expanded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mdf_prod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_expanded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'df_expanded' is not defined"]}]},{"cell_type":"code","source":["if MODE == \"dev\":\n","    df_dev_processed = df_dev.copy()\n","    df_dev_processed[\"수기 라벨링\"] = False\n","    df_dev_processed[\"Implicit\"] = False\n","\n","    drop_list   = []          # 나중에 한꺼번에 삭제\n","    update_rows = {}          # {대상인덱스들: 새 Predicted 값}\n","\n","    for cid, grp in df_dev_processed.groupby(\"Conversation Stream\"):\n","\n","      # 1) 단일 행 & 수기 라벨링\n","      if len(grp) == 1:\n","          i = grp.index[0]\n","\n","          # a) 수기 라벨링\n","          if pd.isna(grp.at[i, \"True_Aspect\"]) and pd.notna(grp.at[i, \"Predicted_Aspect\"]):\n","              df_dev_processed.at[i, \"수기 라벨링\"] = True\n","\n","          # b) Implicit 플래그\n","          if pd.isna(grp.at[i, \"Predicted_Aspect\"]):\n","              df_dev_processed.at[i, \"Implicit\"] = True\n","          continue  # 단일 행 그룹은 여기서 끝\n","\n","      # 2) Samsung 행 여부\n","      mask_s = grp[\"True_Aspect\"].astype(str).str.strip().str.casefold() == \"samsung\"\n","      samsung_idx = grp.index[mask_s]\n","\n","      if len(samsung_idx):\n","          # a) 삭제 예약\n","          drop_list.extend(samsung_idx)\n","\n","          # b) 'True_Aspect가 NaN 이고 Predicted_Aspect는 notna' 행만 골라 True_Aspect 채우기\n","          cond_fill = grp.index.difference(samsung_idx)          # (1) 삼성-행 제외\n","          cond_fill = cond_fill.intersection(                    # (2) 두 조건 모두 만족\n","              grp.index[ grp[\"True_Aspect\"].isna()               #     · True_Aspect 가 NaN\n","                        & grp[\"Predicted_Aspect\"].notna() ]     #     · Predicted_Aspect 는 값이 있음\n","          )\n","\n","          # (3) 업데이트 예약: {행 index : 새 True_Aspect 값(= Predicted_Aspect)}\n","          update_true = {i: df_dev_processed.at[i, \"Predicted_Aspect\"] for i in cond_fill}\n","\n","          # (4) update_rows 사전에 합쳐 둠\n","          update_rows.update(update_true)\n","\n","          # ▶ new: 그룹 전체에 \"if\" 표시\n","          df_dev_processed.loc[grp.index, \"Samsung_branch\"] = \"if_has_samsung\"\n","\n","\n","      # 3) 비-Samsung 행이면서 Predicted도 samsung이 아닐 때\n","      else:\n","          # ── 1) 이 그룹에 Predicted_Aspect == 'samsung' 값이 있는지 확인\n","          has_pa_samsung = (\n","              grp[\"Predicted_Aspect\"]\n","              .astype(str).str.strip().str.casefold()\n","              .eq(\"samsung\")\n","          ).any()\n","\n","          if not has_pa_samsung:                             # ▸ 한 개도 없을 때만 실행\n","              # (1) Predicted_Aspect 가 NaN 이 아닌 행만 골라서\n","              mask_notna = df_dev_processed.loc[grp.index, \"Predicted_Aspect\"].notna()\n","              target_idx = grp.index[mask_notna]\n","\n","              # 그룹 모든 행의 Predicted_Aspect ← 같은 행의 True_Aspect\n","              df_dev_processed.loc[target_idx, \"True_Aspect\"] = (\n","                  df_dev_processed.loc[target_idx, \"Predicted_Aspect\"]\n","              )\n","          # ▶ new: 그룹 전체에 \"else_no_samsung\" 표시\n","          df_dev_processed.loc[grp.index, \"Samsung_branch\"] = \"else_no_samsung\"\n","\n","    # ── 일괄 적용 ─────────────────────────────────────────────\n","    if drop_list:\n","      df_dev_processed.drop(index=drop_list, inplace=True)\n","\n","    for j, new_val in update_rows.items():\n","      if j in df_dev_processed.index:                               # 존재 확인\n","          df_dev_processed.at[j, \"True_Aspect\"] = new_val\n","\n","    # ── (dev) Explicit & Implicit 분리───────────────────────────────────\n","    df_dev_explicit = df_dev_processed[df_dev_processed['Implicit']==False]\n","    df_implicit = df_dev_processed[df_dev_processed['Implicit']==True]"],"metadata":{"id":"8W4QmSV_aQkY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","def merge_rows(g: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"\n","    그룹 g(같은 Conversation  Stream)를 받아서\n","    조건에 맞으면 2행 → 1행으로 축소, 아니면 그대로 반환\n","    \"\"\"\n","    if len(g) == 2:\n","        # NaN 아닌 값이 정확히 하나씩 있는지 확인\n","        true_vals = g[\"True_Aspect\"].dropna().unique()\n","        true_sent = g[\"True_Sentiment\"].dropna().unique()\n","        pred_vals = g[\"Predicted_Aspect\"].dropna().unique()\n","        pred_brands = g[\"Predicted_Brand\"].dropna().unique()\n","\n","        if len(true_vals) == 1 and len(pred_vals) == 1:\n","            # 새 행 만들기: 원본 첫 행을 복사해 값 채움\n","            new_row = g.iloc[0].copy()\n","            new_row[\"True_Aspect\"]      = true_vals[0]\n","            new_row[\"Predicted_Aspect\"] = pred_vals[0]\n","            new_row[\"Predicted_Brand\"]   = pred_brands[0]\n","            new_row[\"True_Sentiment\"]    = true_sent[0]\n","            return pd.DataFrame([new_row])   # 1행짜리 DF 반환\n","\n","    # 조건을 만족하지 않으면 원본 그대로\n","    return g\n","\n","if MODE == \"dev\":\n","  df_explicit = (\n","      df_dev_explicit\n","        .groupby(\"Conversation Stream\", group_keys=False)\n","        .apply(merge_rows)\n","        .reset_index(drop=True)          # 선택: 인덱스 재정렬\n","  )"],"metadata":{"id":"vagVMLUqt5ge"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if MODE == \"prod\":\n","  df_implicit = df_prod[df_prod['Predicted_Aspect'].isna()]\n","  df_explicit = df_prod[~(df_prod['Predicted_Aspect'].isna())]"],"metadata":{"id":"_XXbBW3nxwI4","colab":{"base_uri":"https://localhost:8080/","height":176},"executionInfo":{"status":"error","timestamp":1751601601734,"user_tz":-540,"elapsed":70,"user":{"displayName":"KEARNEY SEMX","userId":"06834010073227309486"}},"outputId":"e3841b01-1433-4779-fd9a-b512104595d5"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'df_prod' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-6-701549432.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mMODE\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"prod\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mdf_implicit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_prod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_prod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Predicted_Aspect'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mdf_explicit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_prod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_prod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Predicted_Aspect'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'df_prod' is not defined"]}]},{"cell_type":"code","source":["df_implicit.to_excel(f\"{OUTPUT_PATH_1}\", index=False)\n","df_explicit.to_excel(f\"{OUTPUT_PATH_2}\", index=False)"],"metadata":{"id":"V4eGRMtNTBRh","colab":{"base_uri":"https://localhost:8080/","height":158},"executionInfo":{"status":"error","timestamp":1751601609620,"user_tz":-540,"elapsed":23,"user":{"displayName":"KEARNEY SEMX","userId":"06834010073227309486"}},"outputId":"0970bf24-4e29-4b66-e34d-254374e61b1e"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'df_implicit' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-7-2045134337.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_implicit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{OUTPUT_PATH_1}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_explicit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{OUTPUT_PATH_2}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'df_implicit' is not defined"]}]},{"cell_type":"markdown","source":["# 참고. Sentiment Analysis 모델링을 위한 전처리 (라벨링 데이터에 끼워맞추기)"],"metadata":{"id":"WviIrv5cSCtK"}},{"cell_type":"code","source":["# # True_Aspect에 값이 있고 Predicted_Aspect와 동일한 행의 개수 계산\n","# count1 = len(df_expanded[(df_expanded['Predicted_Aspect'].notna()) & (df_expanded['True_Aspect'].apply(lambda x: str(x).strip().casefold()) == df_expanded['Predicted_Aspect'].apply(lambda x: str(x).strip().casefold()))])\n","# print(f\"True_Aspect = Predicted_Aspect 행의 개수 (Package 코드): {count1}\")\n","# count2 = len(df_explicit[(df_explicit['True_Aspect'].apply(lambda x: str(x).strip().casefold()) == df_explicit['Predicted_Aspect'].apply(lambda x: str(x).strip().casefold()))])\n","# print(f\"True_Aspect = Predicted_Aspect 행의 개수 (Package 코드): {count2}\")"],"metadata":{"id":"WwvGCaoxymMS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # 1. 엑셀 파일 로드\n","# df = pd.read_excel(\"(raw-2) 0523_S_core_explicit (수정).xlsx\")  # 파일명에 맞게 경로 수정\n","\n","# # 2. 분류기 인스턴스\n","# classifier = BrandClassifier()\n","\n","# # 3. 결과 저장용 리스트\n","# wrong_predictions = []\n","\n","# # 4. 각 행마다 분류하고, 오답일 경우만 저장\n","# for i, row in df.iterrows():\n","#     text = str(row[\"Conversation Stream\"])\n","#     true_aspect = str(row[\"True_Aspect\"]).strip().casefold()\n","#     company = row.get(\"Keywords(Company)\", \"\")\n","\n","#     brands, aspects, detected_brands, detected_aspects = classifier.classify(text)\n","\n","#     true_list = list(map(lambda x : x.strip().casefold(), brands)) + list(map(lambda x: x.strip().casefold(), aspects))\n","\n","#     # 조건 만족 시 Predicted_Aspect를 True_Aspect로 덮어쓰기\n","#     if true_aspect in true_list:\n","#         df.at[i, \"Predicted_Aspect\"] = df.at[i, \"True_Aspect\"]\n","#         df.at[i, \"Modified\"] = True\n","\n","# df_a = df.copy()\n","# len(df[df[\"Predicted_Aspect\"]==df[\"True_Aspect\"]])"],"metadata":{"id":"ixWtjbNwtOVf"},"execution_count":null,"outputs":[]}]}